{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings can capture the \"context\" of a word. We can analyze word embeddings to understand the ideas associated with a word in a corpus.\n",
    "\n",
    "In its most basic sense, word embedding models cluster text. This is how word embedding models understand which words are \"similar\" or \"dissimilar\" to one-another. What does this look like in practice? Like this: if I queried the word \"Texas,\" my model might tell me that \"California\" and \"Illinois\" are similar (because each of these are states). If I instead queried the word \"red\" I might see that \"yellow\" and \"blue\" are similar (becuase these are each colors).\n",
    "\n",
    "We can leverage the insight of a word embeddings model to see how language changed over time or across discourse communities. We can ask questions like: how does the U.S. Congress contextualize \"immigration\" in 2001 compared to 2015? Or, which words does the State School Board associate with \"gay\" in Texas compared to New York? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to reuse our code to import our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(fname):\n",
    "    # Read file as list of lists. \n",
    "    # Then clean the list of lists \n",
    "\n",
    "    with open(fname, newline = '') as f:\n",
    "            reader = json.loads(f.read()) # read the JSON file as a Python object \n",
    "            data = list(reader)[1:]\n",
    "            data = list(map(str, data))\n",
    "\n",
    "    data = [re.sub(r'\\\\\\\\n|\\\\\\\\t', '', word) for word in data] # remove line breaks and tab breaks\n",
    "    data = [re.sub(r'[^\\w\\s]|_', '', word) for word in data] # remove punctuation and underscore\n",
    "    data = [re.sub(r'\\d{1, 3}', '', word) for word in data] # remove digits that are a minimum of 1 and a maximum of 3\n",
    "    data = [re.sub(r'\\w*\\d\\w*', '', word) for word in data] # remove character strings that contain a digit\n",
    "        \n",
    "    data = [word.lower() for word in data]\n",
    "    data = [word.split() for word in data]\n",
    "\n",
    "    for sublist in data:\n",
    "        if 'sentence' in sublist:\n",
    "                sublist.remove('sentence')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/stephbuon/projects/faha/word-embeddings'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.abspath('')\n",
    "\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['senator', 'daschle'],\n",
       " ['is', 'recognized'],\n",
       " ['mr', 'president'],\n",
       " ['on', 'behalf', 'of', 'the', 'entire', 'senate'],\n",
       " ['but', 'especially', 'this', 'senator']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_import(directory + '/congress_2001.json')\n",
    "\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is imported we can now model it. `Word2Vec()` uses a few unfamiliar words. Here, `workers` refers to the number of cores (aka \"brains\") in your laptop. This allows you to allocate work to more cores than just one. `min_count` tells our model not to consider words stated less than 20 times. I chose to remove words stated less than 20 times becuase a model can't accurately assess a word if there are not enought examples of its context. For example, it would be hard to understand the context of the word \"run\" if it is only used once. (Does run refer to an election? Exercise? A tear in some cloth?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 33s, sys: 1.51 s, total: 3min 34s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "period_model = gensim.models.Word2Vec(sentences = data, workers = 8, min_count = 20, vector_size = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Our Word Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this introduction we are working with just one year of the U.S. Congressional Records. Modeling word embeddings can take a long time when working with large data sets, like the Congressional Records for 100 years. \n",
    "\n",
    "Because generating a model is so intensive we would, ideally, only create a model once, not every time we want to do an analysis. Lucky for us we can save our model for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_model.save(directory + '/congress_2001_word_embeddings_model.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save your models anywhere, but they will be a lot easier to find if we designate directories for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Our Word Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load our model whenever we want to work with our word embeddings some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_model = gensim.models.Word2Vec.load(directory + '/congress_2001_word_embeddings_model.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Our Word Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word embeddings model represents the words that are considered similar to one-another based on its corpus. By exploring word embeddings, we can gain insight into how members of Congress associated words with one-another in the year 2001. \n",
    "\n",
    "Scores assigned to word embeddings range from 0 to 1. Larger scores are associated with greater similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which words are considered to be \"most similar\" to one-another within the U.S. Congressional Records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adults', 0.6491211652755737),\n",
       " ('individuals', 0.6041426658630371),\n",
       " ('families', 0.570698618888855),\n",
       " ('lesbians', 0.566820502281189),\n",
       " ('teens', 0.5661625266075134),\n",
       " ('americans', 0.5566259622573853),\n",
       " ('children', 0.5461678504943848),\n",
       " ('servicewomen', 0.5455303192138672),\n",
       " ('people', 0.5398010015487671),\n",
       " ('workers', 0.5377645492553711)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.most_similar('women', topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('servicemen', 0.7953948378562927),\n",
       " ('soldiers', 0.6381202340126038),\n",
       " ('firefighters', 0.6292278170585632),\n",
       " ('heroes', 0.6067168116569519),\n",
       " ('patriots', 0.6038002371788025),\n",
       " ('firemen', 0.57923823595047),\n",
       " ('children', 0.5760605335235596),\n",
       " ('brave', 0.5636528730392456),\n",
       " ('civilians', 0.5574391484260559),\n",
       " ('sailors', 0.5493330955505371)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.most_similar('men', topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twin', 0.7140002250671387),\n",
       " ('camps', 0.675162136554718),\n",
       " ('tents', 0.6718695759773254),\n",
       " ('flames', 0.6657811999320984),\n",
       " ('parked', 0.6589339971542358),\n",
       " ('rubble', 0.6543099284172058),\n",
       " ('khobar', 0.6490092873573303),\n",
       " ('crashes', 0.6387389302253723),\n",
       " ('crash', 0.6295860409736633),\n",
       " ('airliners', 0.6281408667564392)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.most_similar('towers', topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7726640701293945),\n",
       " ('man', 0.7626761794090271),\n",
       " ('hero', 0.7611467838287354),\n",
       " ('journalist', 0.7470694780349731),\n",
       " ('statesman', 0.7453933358192444),\n",
       " ('veteran', 0.7369786500930786),\n",
       " ('aviator', 0.7255291938781738),\n",
       " ('athlete', 0.7117759585380554),\n",
       " ('fireman', 0.6981242299079895),\n",
       " ('politician', 0.6962231993675232)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.most_similar('soldier', topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('climate', 0.6193890571594238),\n",
       " ('globalization', 0.6128581166267395),\n",
       " ('international', 0.6067464351654053),\n",
       " ('warming', 0.5759508609771729),\n",
       " ('worldwide', 0.5730130076408386),\n",
       " ('multilateral', 0.5550599694252014),\n",
       " ('rapid', 0.5546202659606934),\n",
       " ('evolving', 0.5485063791275024),\n",
       " ('strategic', 0.5277345180511475),\n",
       " ('hivaids', 0.5258907675743103)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.most_similar('global', topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtracting Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can substract vectors to see which words are associated with one term, and not the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('female', 0.4222990870475769),\n",
       " ('clinics', 0.41148972511291504),\n",
       " ('immunizations', 0.40906789898872375),\n",
       " ('hospitals', 0.40902236104011536),\n",
       " ('exams', 0.39813071489334106),\n",
       " ('mental', 0.3952828347682953),\n",
       " ('physicians', 0.39134857058525085),\n",
       " ('psychiatrists', 0.3881763517856598),\n",
       " ('medical', 0.3865758180618286),\n",
       " ('screenings', 0.3844527304172516)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words are associated with woman and not man? \n",
    "\n",
    "diff = period_model.wv['woman'] - period_model.wv['man']\n",
    "period_model.wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.4958917498588562),\n",
       " ('bipartisanship', 0.40711140632629395),\n",
       " ('symbolize', 0.3811882436275482),\n",
       " ('billand', 0.3657127320766449),\n",
       " ('preaching', 0.36058422923088074),\n",
       " ('honesty', 0.35733601450920105),\n",
       " ('humility', 0.3560566306114197),\n",
       " ('gesture', 0.35543292760849),\n",
       " ('embodiment', 0.35346508026123047),\n",
       " ('mighty', 0.3475883901119232)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words are associated with man and not woman? \n",
    "\n",
    "diff = period_model.wv['man'] - period_model.wv['woman']\n",
    "period_model.wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Similarity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the score that represents how \"similar\" any two words are within a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6381203"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.similarity('soldiers', 'men')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.029213697"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.similarity('christian', 'rational')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6381203"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_model.wv.similarity('soldiers', 'men')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
